# ============================================================================
# æ”¹è¿›çš„æ–‡ä»¶ç®¡ç†å™¨ - æ”¯æŒå¤šç§å­˜å‚¨åè®®
# ============================================================================

import asyncio
import hashlib
import io
import json
import uuid
from abc import ABC, abstractmethod
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Dict, Any, Optional, Union, BinaryIO, List, Literal, Tuple

import aioboto3
import aiofiles
from botocore.exceptions import ClientError
from pydantic import BaseModel, Field


# ============================================================================
# å­˜å‚¨ç±»å‹æšä¸¾
# ============================================================================

class StorageType(Enum):
    """å­˜å‚¨ç±»å‹æšä¸¾"""
    LOCAL = "local"
    S3 = "s3"
    # æœªæ¥å¯ä»¥æ·»åŠ æ›´å¤šç±»å‹
    # AZURE = "azure"
    # GCS = "gcs"
    # OSS = "oss"


# ============================================================================
# é…ç½®ç±»
# ============================================================================

class StorageConfig(BaseModel):
    """å­˜å‚¨é…ç½®åŸºç±»"""
    storage_type: StorageType
    metadata_backend: str = "json"  # json, redis, dynamodbç­‰
    enable_versioning: bool = False
    enable_encryption: bool = False

    class Config:
        use_enum_values = False


class LocalStorageConfig(StorageConfig):
    """æœ¬åœ°å­˜å‚¨é…ç½®"""
    base_dir: str
    temp_dir: Optional[str] = Field(default="/tmp/local_cache", description="ä¸´æ—¶æ–‡ä»¶ç›®å½•")
    storage_type: StorageType = Field(default=StorageType.LOCAL, description="localå­˜å‚¨ç±»å‹")


class S3StorageConfig(StorageConfig):
    """S3å­˜å‚¨é…ç½®"""
    bucket_name: str
    region_name: str = "us-east-1"
    endpoint_url: Optional[str] = None  # ç”¨äºS3å…¼å®¹æœåŠ¡å¦‚MinIO
    access_key_id: Optional[str] = None
    secret_access_key: Optional[str] = None
    prefix: str = ""  # S3é”®å‰ç¼€
    temp_dir: str = "/tmp/s3_cache"
    storage_type: StorageType = Field(default=StorageType.S3, description="s3å­˜å‚¨ç±»å‹")


# ============================================================================
# æ–‡ä»¶å…ƒæ•°æ®ç±»
# ============================================================================

class FileMetadata(BaseModel):
    """æ–‡ä»¶å…ƒæ•°æ®"""
    file_id: str
    filename: str
    category: str
    storage_path: str  # ç›¸å¯¹è·¯å¾„æˆ–S3 key
    size: int
    hash: str
    created_at: datetime
    updated_at: Optional[datetime] = None
    storage_type: StorageType = StorageType.LOCAL
    content_type: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)

    class Config:
        use_enum_values = False
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'file_id': self.file_id,
            'filename': self.filename,
            'category': self.category,
            'storage_path': self.storage_path,
            'size': self.size,
            'hash': self.hash,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat() if self.updated_at else None,
            'storage_type': self.storage_type.value,
            'content_type': self.content_type,
            'metadata': self.metadata
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'FileMetadata':
        """ä»å­—å…¸åˆ›å»º"""
        data = data.copy()
        data['created_at'] = datetime.fromisoformat(data['created_at'])
        if data.get('updated_at'):
            data['updated_at'] = datetime.fromisoformat(data['updated_at'])
        data['storage_type'] = StorageType(data.get('storage_type', 'local'))
        return cls(**data)


# ============================================================================
# å­˜å‚¨æ¥å£
# ============================================================================

class FileStorageInterface(ABC):
    """æ–‡ä»¶å­˜å‚¨æŠ½è±¡æ¥å£"""

    @abstractmethod
    async def connect(self) -> None:
        """è¿æ¥åˆ°å­˜å‚¨æœåŠ¡"""
        pass

    @abstractmethod
    async def disconnect(self) -> None:
        """æ–­å¼€å­˜å‚¨æœåŠ¡è¿æ¥"""
        pass

    @abstractmethod
    async def save(self,
                   data: Union[bytes, BinaryIO],
                   path: str,
                   content_type: Optional[str] = None) -> Dict[str, Any]:
        """ä¿å­˜æ–‡ä»¶"""
        pass

    @abstractmethod
    async def load(self, path: str) -> bytes:
        """åŠ è½½æ–‡ä»¶å†…å®¹"""
        pass

    @abstractmethod
    async def load_stream(self, path: str) -> BinaryIO:
        """åŠ è½½æ–‡ä»¶å¹¶è¿”å›æµå¯¹è±¡"""
        pass

    @abstractmethod
    async def exists(self, path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        pass

    @abstractmethod
    async def delete(self, path: str) -> bool:
        """åˆ é™¤æ–‡ä»¶"""
        pass

    @abstractmethod
    async def list_files(self, prefix: str = "") -> List[str]:
        """åˆ—å‡ºæ–‡ä»¶"""
        pass

    @abstractmethod
    async def get_file_info(self, path: str) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        pass

    @abstractmethod
    async def get_temp_path(self, path: str) -> str:
        """è·å–ç”¨äºå¤„ç†çš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        pass

    @abstractmethod
    async def copy(self, src_path: str, dst_path: str) -> bool:
        """å¤åˆ¶æ–‡ä»¶"""
        pass

    @abstractmethod
    async def move(self, src_path: str, dst_path: str) -> bool:
        """ç§»åŠ¨æ–‡ä»¶"""
        pass


# ============================================================================
# æœ¬åœ°æ–‡ä»¶å­˜å‚¨å®ç°
# ============================================================================

class LocalFileStorage(FileStorageInterface):
    """æœ¬åœ°æ–‡ä»¶å­˜å‚¨å®ç°"""

    def __init__(self, config: LocalStorageConfig):
        self.config = config
        self.base_dir = Path(config.base_dir)
        self.temp_dir = Path(config.temp_dir)

    async def connect(self) -> None:
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir.mkdir(parents=True, exist_ok=True)

    async def disconnect(self) -> None:
        """æœ¬åœ°å­˜å‚¨æ— éœ€æ–­å¼€è¿æ¥"""
        pass

    async def save(self,
                   data: Union[bytes, BinaryIO],
                   path: str,
                   content_type: Optional[str] = None) -> Dict[str, Any]:
        """ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°"""
        full_path = self.base_dir / path
        full_path.parent.mkdir(parents=True, exist_ok=True)

        # å¼‚æ­¥å†™å…¥æ–‡ä»¶
        if isinstance(data, bytes):
            async with aiofiles.open(full_path, 'wb') as f:
                await f.write(data)
            size = len(data)
        else:
            # å¦‚æœæ˜¯æ–‡ä»¶å¯¹è±¡ï¼Œå…ˆè¯»å–åˆ°å†…å­˜
            if hasattr(data, 'read'):
                content = data.read()
                async with aiofiles.open(full_path, 'wb') as f:
                    await f.write(content)
                size = len(content)
            else:
                raise ValueError("Unsupported data type")

        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        file_hash = await self._calculate_file_hash(full_path)

        return {
            'size': size,
            'hash': file_hash,
            'path': str(full_path),
            'content_type': content_type
        }

    async def load(self, path: str) -> bytes:
        """ä»æœ¬åœ°åŠ è½½æ–‡ä»¶"""
        full_path = self.base_dir / path

        if not full_path.exists():
            raise FileNotFoundError(f"File not found: {path}")

        async with aiofiles.open(full_path, 'rb') as f:
            return await f.read()

    async def load_stream(self, path: str) -> BinaryIO:
        """ä»æœ¬åœ°åŠ è½½æ–‡ä»¶å¹¶è¿”å›æµå¯¹è±¡"""
        full_path = self.base_dir / path

        if not full_path.exists():
            raise FileNotFoundError(f"File not found: {path}")

        # è¯»å–æ–‡ä»¶å†…å®¹åˆ°å†…å­˜å¹¶è¿”å›BytesIOæµ
        async with aiofiles.open(full_path, 'rb') as f:
            content = await f.read()

        return io.BytesIO(content)

    async def exists(self, path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        full_path = self.base_dir / path
        return full_path.exists()

    async def delete(self, path: str) -> bool:
        """åˆ é™¤æœ¬åœ°æ–‡ä»¶"""
        full_path = self.base_dir / path

        if full_path.exists():
            full_path.unlink()
            return True
        return False

    async def list_files(self, prefix: str = "") -> List[str]:
        """åˆ—å‡ºæœ¬åœ°æ–‡ä»¶"""
        search_path = self.base_dir / prefix

        if not search_path.exists():
            return []

        files = []
        for file_path in search_path.rglob("*"):
            if file_path.is_file():
                relative_path = file_path.relative_to(self.base_dir)
                files.append(str(relative_path))

        return files

    async def get_file_info(self, path: str) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        full_path = self.base_dir / path

        if not full_path.exists():
            raise FileNotFoundError(f"File not found: {path}")

        stat = full_path.stat()
        file_hash = await self._calculate_file_hash(full_path)

        return {
            'size': stat.st_size,
            'created_at': datetime.fromtimestamp(stat.st_ctime),
            'updated_at': datetime.fromtimestamp(stat.st_mtime),
            'hash': file_hash
        }

    async def get_temp_path(self, path: str) -> str:
        """è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼ˆæœ¬åœ°å­˜å‚¨ç›´æ¥è¿”å›åŸè·¯å¾„ï¼‰"""
        full_path = self.base_dir / path
        return str(full_path)

    async def copy(self, src_path: str, dst_path: str) -> bool:
        """å¤åˆ¶æ–‡ä»¶"""
        src_full = self.base_dir / src_path
        dst_full = self.base_dir / dst_path

        if not src_full.exists():
            return False

        dst_full.parent.mkdir(parents=True, exist_ok=True)

        # å¼‚æ­¥å¤åˆ¶
        async with aiofiles.open(src_full, 'rb') as src:
            async with aiofiles.open(dst_full, 'wb') as dst:
                await dst.write(await src.read())

        return True

    async def move(self, src_path: str, dst_path: str) -> bool:
        """ç§»åŠ¨æ–‡ä»¶"""
        src_full = self.base_dir / src_path
        dst_full = self.base_dir / dst_path

        if not src_full.exists():
            return False

        dst_full.parent.mkdir(parents=True, exist_ok=True)
        src_full.rename(dst_full)
        return True

    async def _calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
        hash_md5 = hashlib.md5()

        async with aiofiles.open(file_path, 'rb') as f:
            while chunk := await f.read(8192):
                hash_md5.update(chunk)

        return hash_md5.hexdigest()


# ============================================================================
# S3æ–‡ä»¶å­˜å‚¨å®ç°
# ============================================================================

class S3FileStorage(FileStorageInterface):
    """S3æ–‡ä»¶å­˜å‚¨å®ç°"""

    def __init__(self, config: S3StorageConfig):
        self.config = config
        self.session = None
        self.s3_client = None
        self.temp_dir = Path(config.temp_dir)
        self.save_chunk_size = 1024 * 1024

    async def connect(self) -> None:
        """è¿æ¥åˆ°S3"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºS3ä¼šè¯
        self.session = aioboto3.Session(
            aws_access_key_id=self.config.access_key_id,
            aws_secret_access_key=self.config.secret_access_key,
            region_name=self.config.region_name
        )

        # æµ‹è¯•è¿æ¥
        async with self.session.client(
                's3',
                endpoint_url=self.config.endpoint_url
        ) as s3:
            try:
                await s3.head_bucket(Bucket=self.config.bucket_name)
            except ClientError:
                # å°è¯•åˆ›å»ºbucket
                await s3.create_bucket(Bucket=self.config.bucket_name)

    async def disconnect(self) -> None:
        """æ–­å¼€S3è¿æ¥"""
        # aioboto3ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œæ— éœ€æ˜¾å¼æ–­å¼€
        pass

    def _get_s3_key(self, path: str) -> str:
        """è·å–S3é”®"""
        if self.config.prefix:
            return f"{self.config.prefix}/{path}"
        return path

    async def save(self,
                   data: Union[bytes, BinaryIO],
                   path: str,
                   content_type: Optional[str] = None) -> Dict[str, Any]:
        """ä¿å­˜æ–‡ä»¶åˆ°S3"""
        s3_key = self._get_s3_key(path)

        # å‡†å¤‡ä¸Šä¼ æ•°æ®
        if isinstance(data, bytes):
            file_obj = io.BytesIO(data)
            size = len(data)
            # è®¡ç®—å“ˆå¸Œ
            file_hash = hashlib.md5(data).hexdigest()
        else:
            # å¦‚æœæ˜¯æ–‡ä»¶å¯¹è±¡ï¼Œè¯»å–å†…å®¹
            content = data.read() if hasattr(data, 'read') else data
            file_obj = io.BytesIO(content)
            size = len(content)
            file_hash = hashlib.md5(content).hexdigest()

        # ä¸Šä¼ åˆ°S3
        async with self.session.client('s3', endpoint_url=self.config.endpoint_url) as s3:
            extra_args = {}
            if content_type:
                extra_args['ContentType'] = content_type

            await s3.put_object(
                Bucket=self.config.bucket_name,
                Key=s3_key,
                Body=file_obj.getvalue(),
                **extra_args
            )

        return {
            'size': size,
            'hash': file_hash,
            'path': s3_key,
            'content_type': content_type
        }

    async def load(self, path: str) -> bytes:
        """ä»S3åŠ è½½æ–‡ä»¶"""
        s3_key = self._get_s3_key(path)

        async with self.session.client('s3', endpoint_url=self.config.endpoint_url) as s3:
            try:
                response = await s3.get_object(
                    Bucket=self.config.bucket_name,
                    Key=s3_key
                )
                return await response['Body'].read()
            except ClientError as e:
                if e.response['Error']['Code'] == 'NoSuchKey':
                    raise FileNotFoundError(f"File not found: {path}")
                raise

    async def load_stream(self, path: str) -> BinaryIO:
        """ä»S3åŠ è½½æ–‡ä»¶å¹¶è¿”å›æµå¯¹è±¡"""
        s3_key = self._get_s3_key(path)

        async with self.session.client('s3', endpoint_url=self.config.endpoint_url) as s3:
            try:
                response = await s3.get_object(
                    Bucket=self.config.bucket_name,
                    Key=s3_key
                )
                content = io.BytesIO()
                body = response["Body"]

                # Stream the data in chunks
                while True:
                    chunk = await body.read(self.save_chunk_size)
                    if not chunk:
                        break
                    content.write(chunk)

                content.seek(0)
                return content
            except Exception as e:
                if e.response['Error']['Code'] == 'NoSuchKey':
                    raise FileNotFoundError(f"File not found: {path}")
                raise

    async def exists(self, path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        s3_key = self._get_s3_key(path)

        async with self.session.client('s3', endpoint_url=self.config.endpoint_url) as s3:
            try:
                await s3.head_object(
                    Bucket=self.config.bucket_name,
                    Key=s3_key
                )
                return True
            except ClientError:
                return False

    async def delete(self, path: str) -> bool:
        """åˆ é™¤S3æ–‡ä»¶"""
        s3_key = self._get_s3_key(path)

        async with self.session.client('s3', endpoint_url=self.config.endpoint_url) as s3:
            try:
                await s3.delete_object(
                    Bucket=self.config.bucket_name,
                    Key=s3_key
                )
                return True
            except ClientError:
                return False

    async def list_files(self, prefix: str = "") -> List[str]:
        """åˆ—å‡ºS3æ–‡ä»¶"""
        list_prefix = self._get_s3_key(prefix)
        files = []

        async with self.session.client('s3', endpoint_url=self.config.endpoint_url) as s3:
            paginator = s3.get_paginator('list_objects_v2')

            async for page in paginator.paginate(
                    Bucket=self.config.bucket_name,
                    Prefix=list_prefix
            ):
                if 'Contents' in page:
                    for obj in page['Contents']:
                        # ç§»é™¤é…ç½®çš„å‰ç¼€
                        key = obj['Key']
                        if self.config.prefix and key.startswith(self.config.prefix + '/'):
                            key = key[len(self.config.prefix) + 1:]
                        files.append(key)

        return files

    async def get_file_info(self, path: str) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        s3_key = self._get_s3_key(path)

        async with self.session.client('s3', endpoint_url=self.config.endpoint_url) as s3:
            try:
                response = await s3.head_object(
                    Bucket=self.config.bucket_name,
                    Key=s3_key
                )

                return {
                    'size': response['ContentLength'],
                    'created_at': response.get('LastModified'),
                    'updated_at': response.get('LastModified'),
                    'hash': response.get('ETag', '').strip('"'),
                    'content_type': response.get('ContentType')
                }
            except ClientError as e:
                if e.response['Error']['Code'] == '404':
                    raise FileNotFoundError(f"File not found: {path}")
                raise

    async def get_temp_path(self, path: str) -> str:
        """ä¸‹è½½S3æ–‡ä»¶åˆ°ä¸´æ—¶è·¯å¾„"""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_file = self.temp_dir / f"s3_temp_{uuid.uuid4().hex}_{Path(path).name}"

        # ä¸‹è½½æ–‡ä»¶
        content = await self.load(path)

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        async with aiofiles.open(temp_file, 'wb') as f:
            await f.write(content)

        return str(temp_file)

    async def copy(self, src_path: str, dst_path: str) -> bool:
        """å¤åˆ¶S3æ–‡ä»¶"""
        src_key = self._get_s3_key(src_path)
        dst_key = self._get_s3_key(dst_path)

        async with self.session.client('s3', endpoint_url=self.config.endpoint_url) as s3:
            try:
                await s3.copy_object(
                    Bucket=self.config.bucket_name,
                    CopySource={'Bucket': self.config.bucket_name, 'Key': src_key},
                    Key=dst_key
                )
                return True
            except ClientError:
                return False

    async def move(self, src_path: str, dst_path: str) -> bool:
        """ç§»åŠ¨S3æ–‡ä»¶"""
        # S3æ²¡æœ‰åŸç”Ÿçš„ç§»åŠ¨æ“ä½œï¼Œéœ€è¦å¤åˆ¶ååˆ é™¤
        if await self.copy(src_path, dst_path):
            return await self.delete(src_path)
        return False


# ============================================================================
# å…ƒæ•°æ®å­˜å‚¨æ¥å£
# ============================================================================

class MetadataStorageInterface(ABC):
    """å…ƒæ•°æ®å­˜å‚¨æ¥å£"""

    @abstractmethod
    async def save(self, metadata: Dict[str, FileMetadata]) -> None:
        """ä¿å­˜å…ƒæ•°æ®"""
        pass

    @abstractmethod
    async def load(self) -> Dict[str, FileMetadata]:
        """åŠ è½½å…ƒæ•°æ®"""
        pass

    @abstractmethod
    async def get(self, file_id: str) -> Optional[FileMetadata]:
        """è·å–å•ä¸ªæ–‡ä»¶å…ƒæ•°æ®"""
        pass

    @abstractmethod
    async def delete(self, file_id: str) -> bool:
        """åˆ é™¤å…ƒæ•°æ®"""
        pass

    @abstractmethod
    async def update(self, file_id: str, updates: Dict[str, Any]) -> bool:
        """æ›´æ–°å…ƒæ•°æ®"""
        pass


# ============================================================================
# JSONå…ƒæ•°æ®å­˜å‚¨å®ç°
# ============================================================================

class JsonMetadataStorage(MetadataStorageInterface):
    """JSONæ–‡ä»¶å…ƒæ•°æ®å­˜å‚¨"""

    def __init__(self, storage: FileStorageInterface, metadata_path: str = "metadata.json"):
        self.storage = storage
        self.metadata_path = metadata_path
        self._cache: Dict[str, FileMetadata] = {}
        self._loaded = False

    async def save(self, metadata: Dict[str, FileMetadata]) -> None:
        """ä¿å­˜å…ƒæ•°æ®åˆ°JSON"""
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        data = {}
        for file_id, meta in metadata.items():
            data[file_id] = meta.to_dict()

        # ä¿å­˜åˆ°å­˜å‚¨
        json_data = json.dumps(data, ensure_ascii=False, indent=2)
        await self.storage.save(
            json_data.encode('utf-8'),
            self.metadata_path,
            content_type='application/json'
        )

        self._cache = metadata.copy()

    async def load(self) -> Dict[str, FileMetadata]:
        """ä»JSONåŠ è½½å…ƒæ•°æ®"""
        if self._loaded:
            return self._cache

        try:
            content = await self.storage.load(self.metadata_path)
            data = json.loads(content.decode('utf-8'))

            self._cache = {}
            for file_id, meta_dict in data.items():
                self._cache[file_id] = FileMetadata.from_dict(meta_dict)

            self._loaded = True
            return self._cache

        except FileNotFoundError:
            self._cache = {}
            self._loaded = True
            return self._cache

    async def get(self, file_id: str) -> Optional[FileMetadata]:
        """è·å–å•ä¸ªæ–‡ä»¶å…ƒæ•°æ®"""
        if not self._loaded:
            await self.load()
        return self._cache.get(file_id)

    async def delete(self, file_id: str) -> bool:
        """åˆ é™¤å…ƒæ•°æ®"""
        if not self._loaded:
            await self.load()

        if file_id in self._cache:
            del self._cache[file_id]
            await self.save(self._cache)
            return True
        return False

    async def update(self, file_id: str, updates: Dict[str, Any]) -> bool:
        """æ›´æ–°å…ƒæ•°æ®"""
        if not self._loaded:
            await self.load()

        if file_id in self._cache:
            meta = self._cache[file_id]
            for key, value in updates.items():
                if hasattr(meta, key):
                    setattr(meta, key, value)
            meta.updated_at = datetime.now()
            await self.save(self._cache)
            return True
        return False


# ============================================================================
# æ”¹è¿›çš„æ–‡ä»¶ç®¡ç†å™¨
# ============================================================================

class ImprovedFileManager:
    """æ”¹è¿›çš„æ–‡ä»¶ç®¡ç†å™¨ - æ”¯æŒå¤šç§å­˜å‚¨åè®®"""

    def __init__(self,
                 storage: FileStorageInterface,
                 metadata_storage: Optional[MetadataStorageInterface] = None):
        """
        åˆå§‹åŒ–æ–‡ä»¶ç®¡ç†å™¨

        Args:
            storage: æ–‡ä»¶å­˜å‚¨æ¥å£å®ä¾‹
            metadata_storage: å…ƒæ•°æ®å­˜å‚¨æ¥å£å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        self.storage = storage
        self.metadata_storage = metadata_storage or JsonMetadataStorage(storage)
        self.metadata: Dict[str, FileMetadata] = {}
        self._initialized = False

    async def initialize(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        if self._initialized:
            return

        # è¿æ¥å­˜å‚¨
        await self.storage.connect()

        # åŠ è½½å…ƒæ•°æ®
        self.metadata = await self.metadata_storage.load()

        self._initialized = True
        print(f"FileManager initialized with {len(self.metadata)} files")

    async def save_file(self,
                        data: Union[bytes, BinaryIO],
                        filename: str,
                        category: str = "general",
                        metadata: Optional[Dict] = None,
                        content_type: Optional[str] = None) -> str:
        """
        ä¿å­˜æ–‡ä»¶

        Args:
            data: æ–‡ä»¶æ•°æ®æˆ–æ–‡ä»¶å¯¹è±¡
            filename: æ–‡ä»¶å
            category: æ–‡ä»¶åˆ†ç±»
            metadata: é™„åŠ å…ƒæ•°æ®
            content_type: å†…å®¹ç±»å‹

        Returns:
            æ–‡ä»¶ID
        """
        if not self._initialized:
            await self.initialize()

        # ç”Ÿæˆæ–‡ä»¶IDå’Œè·¯å¾„
        file_id = str(uuid.uuid4())
        file_path = f"{category}/{file_id}_{filename}"

        # ä¿å­˜æ–‡ä»¶åˆ°å­˜å‚¨
        save_result = await self.storage.save(data, file_path, content_type)

        # åˆ›å»ºå…ƒæ•°æ®
        file_metadata = FileMetadata(
            file_id=file_id,
            filename=filename,
            category=category,
            storage_path=file_path,
            size=save_result['size'],
            hash=save_result['hash'],
            created_at=datetime.now(),
            storage_type=self.storage.config.storage_type,
            content_type=content_type,
            metadata=metadata or {}
        )

        # ä¿å­˜å…ƒæ•°æ®
        self.metadata[file_id] = file_metadata
        await self.metadata_storage.save(self.metadata)

        return file_id

    async def get_file_path(self, file_id: str) -> Optional[str]:
        """
        è·å–æ–‡ä»¶è·¯å¾„ï¼ˆå¯¹äºéœ€è¦æœ¬åœ°è·¯å¾„çš„åœºæ™¯ï¼‰

        å¯¹äºS3ç­‰è¿œç¨‹å­˜å‚¨ï¼Œä¼šä¸‹è½½åˆ°ä¸´æ—¶ç›®å½•
        """
        if not self._initialized:
            await self.initialize()

        if file_id not in self.metadata:
            return None

        file_meta = self.metadata[file_id]

        # è·å–ä¸´æ—¶è·¯å¾„ï¼ˆæœ¬åœ°å­˜å‚¨ç›´æ¥è¿”å›ï¼Œè¿œç¨‹å­˜å‚¨ä¼šä¸‹è½½ï¼‰
        temp_path = await self.storage.get_temp_path(file_meta.storage_path)
        return temp_path

    async def load_file(self, file_id: str) -> Tuple[Optional[FileMetadata], Optional[bytes]]:
        """åŠ è½½æ–‡ä»¶å†…å®¹"""
        if not self._initialized:
            await self.initialize()

        if file_id not in self.metadata:
            return None, None

        file_meta = self.metadata[file_id]
        try:
            return file_meta, await self.storage.load(file_meta.storage_path)
        except FileNotFoundError:
            return None, None

    async def load_file_stream(self, file_id: str) -> Tuple[Optional[FileMetadata], Optional[BinaryIO]]:
        """
        åŠ è½½æ–‡ä»¶å¹¶è¿”å›å…ƒæ•°æ®å’Œæµå¯¹è±¡çš„å…ƒç»„

        Args:
            file_id: æ–‡ä»¶ID

        Returns:
            Tuple[FileMetadata, BinaryIO]: æ–‡ä»¶å…ƒæ•°æ®å’ŒäºŒè¿›åˆ¶æµå¯¹è±¡çš„å…ƒç»„
            å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å› (None, None)
        """
        if not self._initialized:
            await self.initialize()

        if file_id not in self.metadata:
            return None, None

        file_meta = self.metadata[file_id]
        try:
            stream = await self.storage.load_stream(file_meta.storage_path)
            return file_meta, stream
        except FileNotFoundError:
            return None, None

    async def delete_file(self, file_id: str) -> bool:
        """åˆ é™¤æ–‡ä»¶"""
        if not self._initialized:
            await self.initialize()

        if file_id not in self.metadata:
            return False

        file_meta = self.metadata[file_id]

        # åˆ é™¤å­˜å‚¨ä¸­çš„æ–‡ä»¶
        deleted = await self.storage.delete(file_meta.storage_path)

        if deleted:
            # åˆ é™¤å…ƒæ•°æ®
            await self.metadata_storage.delete(file_id)
            del self.metadata[file_id]

        return deleted

    def list_files(self, category: Optional[str] = None) -> List[Dict]:
        """åˆ—å‡ºæ–‡ä»¶"""
        files = []
        for file_id, meta in self.metadata.items():
            if category is None or meta.category == category:
                files.append({
                    'file_id': file_id,
                    'filename': meta.filename,
                    'category': meta.category,
                    'size': meta.size,
                    'created_at': meta.created_at.isoformat(),
                    'metadata': meta.metadata
                })
        return files

    def get_file_by_id(self, file_id: str) -> Optional[FileMetadata]:
        """é€šè¿‡æ–‡ä»¶IDè·å–æ–‡ä»¶å…ƒæ•°æ®"""
        return self.metadata.get(file_id)

    async def copy_file(self, file_id: str, new_category: Optional[str] = None) -> Optional[str]:
        """å¤åˆ¶æ–‡ä»¶"""
        if not self._initialized:
            await self.initialize()

        if file_id not in self.metadata:
            return None

        source_meta = self.metadata[file_id]

        # ç”Ÿæˆæ–°çš„æ–‡ä»¶IDå’Œè·¯å¾„
        new_file_id = str(uuid.uuid4())
        new_category = new_category or source_meta.category
        new_path = f"{new_category}/{new_file_id}_{source_meta.filename}"

        # å¤åˆ¶æ–‡ä»¶
        success = await self.storage.copy(source_meta.storage_path, new_path)

        if success:
            # åˆ›å»ºæ–°çš„å…ƒæ•°æ®
            new_metadata = FileMetadata(
                file_id=new_file_id,
                filename=source_meta.filename,
                category=new_category,
                storage_path=new_path,
                size=source_meta.size,
                hash=source_meta.hash,
                created_at=datetime.now(),
                storage_type=source_meta.storage_type,
                content_type=source_meta.content_type,
                metadata=source_meta.metadata.copy()
            )

            self.metadata[new_file_id] = new_metadata
            await self.metadata_storage.save(self.metadata)

            return new_file_id

        return None

    async def move_file(self, file_id: str, new_category: str) -> bool:
        """ç§»åŠ¨æ–‡ä»¶åˆ°æ–°åˆ†ç±»"""
        if not self._initialized:
            await self.initialize()

        if file_id not in self.metadata:
            return False

        file_meta = self.metadata[file_id]

        # ç”Ÿæˆæ–°è·¯å¾„
        new_path = f"{new_category}/{file_id}_{file_meta.filename}"

        # ç§»åŠ¨æ–‡ä»¶
        success = await self.storage.move(file_meta.storage_path, new_path)

        if success:
            # æ›´æ–°å…ƒæ•°æ®
            file_meta.category = new_category
            file_meta.storage_path = new_path
            file_meta.updated_at = datetime.now()
            await self.metadata_storage.save(self.metadata)

        return success

    async def cleanup_temp_files(self, max_age_hours: int = 24):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        # ä¸»è¦ç”¨äºS3å­˜å‚¨çš„æœ¬åœ°ç¼“å­˜æ¸…ç†
        if hasattr(self.storage, 'temp_dir'):
            import time
            current_time = time.time()
            max_age_seconds = max_age_hours * 3600

            temp_dir = Path(self.storage.temp_dir)
            if temp_dir.exists():
                for file_path in temp_dir.iterdir():
                    if file_path.is_file():
                        file_age = current_time - file_path.stat().st_mtime
                        if file_age > max_age_seconds:
                            file_path.unlink()
                            print(f"Cleaned up temp file: {file_path}")

    # ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ”¯æŒ
    async def __aenter__(self):
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.storage.disconnect()


# ============================================================================
# å­˜å‚¨å·¥å‚
# ============================================================================

class StorageFactory:
    """å­˜å‚¨å·¥å‚ç±»"""

    @staticmethod
    def create_storage(config: StorageConfig) -> FileStorageInterface:
        """æ ¹æ®é…ç½®åˆ›å»ºå­˜å‚¨å®ä¾‹"""
        if isinstance(config, LocalStorageConfig):
            return LocalFileStorage(config)
        elif isinstance(config, S3StorageConfig):
            return S3FileStorage(config)
        else:
            raise ValueError(f"Unsupported storage config type: {type(config)}")

    @staticmethod
    def create_local_storage(base_dir: str, **kwargs) -> LocalFileStorage:
        """åˆ›å»ºæœ¬åœ°å­˜å‚¨"""
        config = LocalStorageConfig(
            storage_type=StorageType.LOCAL,
            base_dir=base_dir,
            **kwargs
        )
        return LocalFileStorage(config)

    @staticmethod
    def create_s3_storage(bucket_name: str,
                          region_name: str = "us-east-1",
                          **kwargs) -> S3FileStorage:
        """åˆ›å»ºS3å­˜å‚¨"""
        config = S3StorageConfig(
            storage_type=StorageType.S3,
            bucket_name=bucket_name,
            region_name=region_name,
            **kwargs
        )
        return S3FileStorage(config)



async def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""

    # ç¤ºä¾‹1ï¼šä½¿ç”¨æœ¬åœ°å­˜å‚¨
    print("=== æœ¬åœ°å­˜å‚¨ç¤ºä¾‹ ===")
    local_config = LocalStorageConfig(
        storage_type=StorageType.LOCAL,
        base_dir="./test_storage",
        temp_dir="./test_storage/temp"
    )

    local_storage = StorageFactory.create_storage(local_config)

    async with ImprovedFileManager(local_storage) as file_manager:
        # ä¿å­˜æ–‡ä»¶
        file_id = await file_manager.save_file(
            b"Hello, Local Storage!",
            "test.txt",
            category="documents",
            metadata={"author": "test"},
            content_type="text/plain"
        )
        print(f"Saved file with ID: {file_id}")

        # è·å–æ–‡ä»¶
        # content = await file_manager.load_file(file_id)
        # print(f"File content: {content.decode('utf-8')}")

        # åˆ—å‡ºæ–‡ä»¶
        files = file_manager.list_files()
        print(f"Files: {files}")


async def quick_test():
    """å¿«é€Ÿæµ‹è¯• MinIO æœåŠ¡"""
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯• MinIO æœåŠ¡...")

    # MinIO é…ç½®
    config = S3StorageConfig(
        storage_type=StorageType.S3,
        bucket_name="quicktest",
        endpoint_url="http://localhost:9000",
        access_key_id="admin",
        secret_access_key="minioadmin123",
        prefix="test"
    )

    storage = StorageFactory.create_storage(config)

    try:
        async with ImprovedFileManager(storage) as fm:
            print("âœ… è¿æ¥æˆåŠŸ")

            # ä¸Šä¼ æµ‹è¯•æ–‡ä»¶
            file_id = await fm.save_file(
                b"Hello MinIO from Python!",
                "hello.txt",
                "test"
            )
            print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_id}")

            # ä¸‹è½½æµ‹è¯•æ–‡ä»¶
            metadata, content = await fm.load_file(file_id)
            print(f"âœ… æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {content.decode()}")

            # åˆ é™¤æµ‹è¯•æ–‡ä»¶
            # await fm.delete_file(file_id)
            # print("âœ… æ–‡ä»¶åˆ é™¤æˆåŠŸ")

            print("ğŸ‰ MinIO æœåŠ¡å·¥ä½œæ­£å¸¸ï¼")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("\nè¯·æ£€æŸ¥:")
        print("1. MinIO æœåŠ¡æ˜¯å¦å¯åŠ¨: podman ps")
        print("2. ç«¯å£æ˜¯å¦æ­£ç¡®: http://localhost:9000")
        print("3. å‡­æ®æ˜¯å¦æ­£ç¡®: minioadmin/minioadmin123")

if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    # asyncio.run(example_usage())
    asyncio.run(quick_test())